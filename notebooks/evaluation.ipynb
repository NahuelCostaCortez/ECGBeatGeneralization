{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nahuel/ecg/generalization/models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nahuel/ecg/generalization/generalization/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd /home/nahuel/ecg/generalization/models\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Agregar la carpeta que contiene 'data.py' al sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../data')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import select_model, ECGModel, evaluate, fine_tune\n",
    "from data import load_data, get_shot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"MIT-toy\"\n",
    "\n",
    "train_dataloader, val_dataloader, test_dataloader, _ = load_data(dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"CNN\"\n",
    "model_module = select_model(model_name)\n",
    "\n",
    "path = \"/home/nahuel/ecg/generalization/models/saved/lightning_logs/version_1/checkpoints/best_model.ckpt\"\n",
    "model = ECGModel.load_from_checkpoint(path, model=model_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on MIT-BIH\n",
      "Accuracy: 0.9794\n",
      "F1 Score: 0.8948\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "\n",
    "print(\"Evaluation on MIT-BIH\")\n",
    "evaluate(model, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero escoger shot=5, 10, 50. Es decir, 5 samples por clase, 10 samples por clase..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dataset = train_dataloader.dataset\n",
    "class_counts = np.unique([label for _, label in dataset], return_counts=True)[1]\n",
    "# Número de clases en tu dataset\n",
    "num_classes = len(class_counts)\n",
    "\n",
    "# Crear subconjuntos para 50, 100, 150 muestras\n",
    "subset_5 = get_shot(dataset, shot=5, num_classes=num_classes)\n",
    "subset_10 = get_shot(dataset, shot=10, num_classes=num_classes)\n",
    "subset_50 = get_shot(dataset, shot=50, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.conv1.weight: False\n",
      "model.conv1.bias: False\n",
      "model.conv2.weight: False\n",
      "model.conv2.bias: False\n",
      "model.conv3.weight: False\n",
      "model.conv3.bias: False\n",
      "model.conv4.weight: False\n",
      "model.conv4.bias: False\n",
      "model.conv5.weight: False\n",
      "model.conv5.bias: False\n",
      "model.conv6.weight: False\n",
      "model.conv6.bias: False\n",
      "model.conv7.weight: False\n",
      "model.conv7.bias: False\n",
      "model.conv8.weight: False\n",
      "model.conv8.bias: False\n",
      "model.fc1.weight: True\n",
      "model.fc1.bias: True\n",
      "model.fc2.weight: True\n",
      "model.fc2.bias: True\n",
      "model.fc3.weight: True\n",
      "model.fc3.bias: True\n",
      "Epoch 1/10, Loss: 0.6024\n",
      "Epoch 2/10, Loss: 0.3030\n",
      "Epoch 3/10, Loss: 0.5283\n",
      "Epoch 4/10, Loss: 0.5303\n",
      "Epoch 5/10, Loss: 0.2561\n",
      "Epoch 6/10, Loss: 0.6047\n",
      "Epoch 7/10, Loss: 0.5209\n",
      "Epoch 8/10, Loss: 0.4964\n",
      "Epoch 9/10, Loss: 0.4889\n",
      "Epoch 10/10, Loss: 0.4234\n"
     ]
    }
   ],
   "source": [
    "fine_tune(model_name, model, subset_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9819\n",
      "F1 Score: 0.9065\n"
     ]
    }
   ],
   "source": [
    "# Evidentemente esto no tiene sentido, porque estoy re-entrenando con\n",
    "# los mismos datos que ya usé para entrenar el modelo. Pero es un ejemplo.\n",
    "evaluate(model, test_dataloader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generalization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
